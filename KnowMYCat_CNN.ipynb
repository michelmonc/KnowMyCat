{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x04Be13JMbfq"
      },
      "outputs": [],
      "source": [
        "#This code was helped by Justing Robert\n",
        "#To run need to do it in Google Colab\n",
        "\"\"\"\n",
        "First code of setting up the CNN, we still need different things like downloading the data\n",
        "and setting up in the right way (path) so that the CNN can access it. We also need later on to do functions to actually test the CNN in a way\n",
        "that we can see the results. To do this I used the tensor flow last thing and I used the last CNN program that we worked on. If you have any questions\n",
        "please text me\n",
        "\n",
        "I moved our imports to a seperate block  so that we could run them before testing any code. - Justin\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #For processing the images so they can be run through the network\n",
        "from tensorflow.keras.models import Sequential #Needed for building the network nodes\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense #Needed for building the Coonvultional layers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwctsc5Jr-vA",
        "outputId": "c8b2f57b-fa6c-403b-c1ee-5d6c25355059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import auth, drive #For accessing the database through drive\n",
        "auth.authenticate_user()\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzSIDqlIcEkN",
        "outputId": "18fed9b2-aaff-4096-edab-597e0159a286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['persian', 'abyssian', 'toyger']\n",
            "['toyger', 'abyssian', 'persian']\n"
          ]
        }
      ],
      "source": [
        "# Define paths to the training and testing data directories\n",
        "\n",
        "datasets = \"/content/drive/MyDrive/410project/dataset/\"\n",
        "\n",
        "train_data_dir = os.path.join(datasets, \"training\")\n",
        "test_data_dir = os.path.join(datasets, \"validation\")\n",
        "\n",
        "print(os.listdir(train_data_dir))\n",
        "print(os.listdir(test_data_dir))\n",
        "#Incase we need access to specific cat breed folders I will make variables with directories to each one\n",
        "\"\"\"See training folders\"\"\"\n",
        "training_persion = os.path.join(train_data_dir, \"persian\")\n",
        "training_abyssian = os.path.join(train_data_dir, \"abyssian\")\n",
        "#training_munchkin = os.path.join(train_data_dir, \"munchkin\")\n",
        "training_toyger = os.path.join(train_data_dir, \"toyger\")\n",
        "\n",
        "\"\"\"See testing folders\"\"\"\n",
        "#testing_munchkin = os.path.join(test_data_dir, \"munchkin\")\n",
        "testing_toyger = os.path.join(test_data_dir, \"toyger\")\n",
        "testing_abyssian = os.path.join(test_data_dir, \"abyssian\")\n",
        "testing_persian = os.path.join(test_data_dir, \"persian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v19sA8vJMd7T"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 250, 250\n",
        "batch_size = 32 # determes the number of samples processed by the model in each training iteration\n",
        "\n",
        "# Create data generors with augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Rescale pixel values to [0,1]\n",
        "    shear_range=0.2,            # Shearing transformation\n",
        "    zoom_range=0.2,             # Zooming transformation\n",
        "    horizontal_flip=True)       # Horizontal flipping\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values for testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJcMhjIQOVDD",
        "outputId": "2146eb8a-753b-478c-d10b-5e274649d388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1077 images belonging to 3 classes.\n",
            "Found 448 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "train_generator is an object that will continuously generate batches of training data from the specified directory\n",
        "with images resized to  dimensions and one encoded class\n",
        "labels suitable for multi-class classification tasks.\n",
        "\n",
        "- train_datagen is a instance of the ImageDataGenerator used to prepocess the images\n",
        "- flow_from_directory method of the ImageDataGenerator class\n",
        "- class_mode specifies the type of labels returned by the generator\n",
        "\"\"\"\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir, target_size=(img_width, img_height), batch_size=batch_size,\n",
        "    class_mode='categorical')  # Use categorical labels for multi-class classification\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir, target_size=(img_width, img_height), batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crI0VGJSOZD7",
        "outputId": "2d0c8f6d-802c-447d-a8b9-3ecf7445158e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 248, 248, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 124, 124, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 122, 122, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 61, 61, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 59, 59, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 29, 29, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 27, 27, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130208 (508.62 KB)\n",
            "Trainable params: 130208 (508.62 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the CNN model\n",
        "model = Sequential()  # Create a sequential model\n",
        "\n",
        "# Adding Convolutional layers with MaxPooling\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6FRykSjOcYz",
        "outputId": "92c464c2-899c-4f80-bf9a-f4fb7636d78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 248, 248, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 124, 124, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 122, 122, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 61, 61, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 59, 59, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 29, 29, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 27, 27, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1638912   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1770659 (6.75 MB)\n",
            "Trainable params: 1770659 (6.75 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Flatten the output from Convolutional layers for input to Dense layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add Dense layers\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(len(train_generator.class_indices), activation='softmax'))  # Output layer\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeQ-KOfPMESd",
        "outputId": "ccdd16f3-31ba-4a7f-b9dd-197d3e0e9872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "31/33 [===========================>..] - ETA: 8s - loss: 1.0144 - accuracy: 0.4437 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 166s 5s/step - loss: 1.0119 - accuracy: 0.4442 - val_loss: 0.9119 - val_accuracy: 0.5312\n",
            "Epoch 2/16\n",
            "33/33 [==============================] - 160s 5s/step - loss: 0.9057 - accuracy: 0.5377 - val_loss: 0.8085 - val_accuracy: 0.5826\n",
            "Epoch 3/16\n",
            "33/33 [==============================] - 162s 5s/step - loss: 0.8241 - accuracy: 0.6044 - val_loss: 0.7515 - val_accuracy: 0.6987\n",
            "Epoch 4/16\n",
            "33/33 [==============================] - 158s 5s/step - loss: 0.6835 - accuracy: 0.7140 - val_loss: 0.7703 - val_accuracy: 0.6853\n",
            "Epoch 5/16\n",
            "33/33 [==============================] - 161s 5s/step - loss: 0.6280 - accuracy: 0.7340 - val_loss: 0.6202 - val_accuracy: 0.7165\n",
            "Epoch 6/16\n",
            "33/33 [==============================] - 158s 5s/step - loss: 0.6095 - accuracy: 0.7512 - val_loss: 0.6197 - val_accuracy: 0.7299\n",
            "Epoch 7/16\n",
            "33/33 [==============================] - 160s 5s/step - loss: 0.5186 - accuracy: 0.7998 - val_loss: 0.4859 - val_accuracy: 0.8013\n",
            "Epoch 8/16\n",
            "33/33 [==============================] - 161s 5s/step - loss: 0.4981 - accuracy: 0.7998 - val_loss: 0.5042 - val_accuracy: 0.8036\n",
            "Epoch 9/16\n",
            "33/33 [==============================] - 159s 5s/step - loss: 0.4887 - accuracy: 0.7979 - val_loss: 0.4161 - val_accuracy: 0.8304\n",
            "Epoch 10/16\n",
            "33/33 [==============================] - 161s 5s/step - loss: 0.4635 - accuracy: 0.8246 - val_loss: 0.4619 - val_accuracy: 0.8147\n",
            "Epoch 11/16\n",
            "33/33 [==============================] - 157s 5s/step - loss: 0.4778 - accuracy: 0.8132 - val_loss: 0.4521 - val_accuracy: 0.8259\n",
            "Epoch 12/16\n",
            "33/33 [==============================] - 159s 5s/step - loss: 0.4390 - accuracy: 0.8351 - val_loss: 0.4405 - val_accuracy: 0.8438\n",
            "Epoch 13/16\n",
            "33/33 [==============================] - 162s 5s/step - loss: 0.3836 - accuracy: 0.8418 - val_loss: 0.4156 - val_accuracy: 0.8281\n",
            "Epoch 14/16\n",
            "33/33 [==============================] - 161s 5s/step - loss: 0.3838 - accuracy: 0.8484 - val_loss: 0.4230 - val_accuracy: 0.8393\n",
            "Epoch 15/16\n",
            "33/33 [==============================] - 159s 5s/step - loss: 0.3608 - accuracy: 0.8589 - val_loss: 0.4433 - val_accuracy: 0.8214\n",
            "Epoch 16/16\n",
            "33/33 [==============================] - 160s 5s/step - loss: 0.3251 - accuracy: 0.8751 - val_loss: 0.3887 - val_accuracy: 0.8594\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch,\n",
        "    epochs=16,                                              # Number of epochs\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size)  # Number of validation steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPWRYBThOeg8"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/410project/saved_model/cat_breed_classifier_model.no_munch_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWQmk1TdEddJ"
      },
      "outputs": [],
      "source": [
        "#Loading the model\n",
        "model = load_model('/content/drive/MyDrive/410project/saved_model/cat_breed_classifier_model.no_munch_2')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2wUxzLNBRaN",
        "outputId": "a7abd662-b60e-4367-868f-3d32735fa4d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 - 18s - loss: 0.3880 - accuracy: 0.8597 - 18s/epoch - 1s/step\n",
            "\n",
            "Test Accuracy: 0.8596882224082947\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Accuracy of the model\n",
        "# validation_generator yields batches of images and their corresponding labels from the specified directory.IF we do not like how it works we can change it\n",
        "test_loss, test_accuracy = model.evaluate(validation_generator, verbose = 2)\n",
        "\n",
        "# Printing the accuracy\n",
        "print('\\nTest Accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axFA5hF9DK5b",
        "outputId": "ee93426f-d84b-4d66-978f-d6c39849d7de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 18s 1s/step\n"
          ]
        }
      ],
      "source": [
        "#Prediction\n",
        "probability_model = tf.keras.Sequential([model,\n",
        "                                         tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(validation_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOjK6yMkEhoy"
      },
      "outputs": [],
      "source": [
        "#Preparing the Input Data\n",
        "\n",
        "# Load and preprocess the input image in order for it to be the same way as the training set\n",
        "img_path = \"/content/drive/MyDrive/410project/test_images/testing_code.webp\" #Add after test_images the actual image name\n",
        "img = image.load_img(img_path, target_size=(250, 250))  # Resize image to match model input dimensions\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = img_array / 255.0  # Normalize pixel values\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpTabiXIEm3z",
        "outputId": "feeadb05-b70b-450d-e924-c9c2e5c5f2d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 250, 250, 3)\n",
            "(1, 250, 250, 3)\n",
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        }
      ],
      "source": [
        "#Interpreting Predictions\n",
        "print(model.input_shape)\n",
        "print(img_array.shape)\n",
        "\n",
        "prediction_interpretation = model.predict(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DovMWI9kEq-d"
      },
      "outputs": [],
      "source": [
        "# Interpreting the prediction\n",
        "predicted_class_index = np.argmax(prediction_interpretation) # argmax is used to find the index of the class with the highes probability.\n",
        "predicted_class_probability = np.max(prediction_interpretation) #use max to show the one with the highest probability\n",
        "class_labels = [\"persian\",\"abyssian\",\"toyger\"] # ,\"munchkin\"\n",
        "predicted_class_label = class_labels[predicted_class_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJdTMzdMQfYX",
        "outputId": "5d05698d-43b1-490b-f316-d2ad8fc5d666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class:  toyger\n",
            "Predicted Probability:  0.9999975\n"
          ]
        }
      ],
      "source": [
        "print('Predicted Class: ', predicted_class_label)\n",
        "print('Predicted Probability: ', predicted_class_probability)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
